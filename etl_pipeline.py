import requests
import pandas as pd
import pandas_ta as ta
import numpy as np
import sqlite3
import logging
import time
from datetime import datetime
from dump_core.config import *

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BASE_URL = "https://fapi.binance.com/fapi/v1/klines"

# –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
TF_MS = {
    "1m": 60_000,
    "5m": 300_000,
    "15m": 900_000,
    "1h": 3_600_000,
    "4h": 14_400_000,
    "1d": 86_400_000,
}


def init_db():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
    conn = sqlite3.connect(DB_PATH)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS candles (
            symbol TEXT,
            timeframe TEXT,
            open_time INTEGER,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume REAL,
            quote_volume REAL,
            PRIMARY KEY (symbol, timeframe, open_time)
        )
    """)
    conn.commit()
    return conn


def fetch_data(conn, symbol, timeframe):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å Binance API –Ω–∞—á–∏–Ω–∞—è —Å START_DATE –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏ –≤ –ë–î.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É.
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª –¥–ª—è API (BTC/USDT -> BTCUSDT)
    api_symbol = symbol.replace("/", "")
    
    cur = conn.cursor()
    cur.execute("SELECT MAX(open_time) FROM candles WHERE symbol=? AND timeframe=?", (symbol, timeframe))
    last_ts = cur.fetchone()[0]
    
    # –°—Ç–∞—Ä—Ç —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏ –≤ –ë–î –∏–ª–∏ —Å START_DATE
    if last_ts:
        start_ts = last_ts + 1
    else:
        start_ts = int(datetime.fromisoformat(START_DATE).timestamp() * 1000)
    
    # –ö–æ–Ω–µ—Ü: END_DATE –∏–ª–∏ —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
    end_ts = int(datetime.fromisoformat(END_DATE).timestamp() * 1000) if END_DATE else None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤—ã—à–ª–∏ –ª–∏ –º—ã –∑–∞ –ø—Ä–µ–¥–µ–ª—ã END_DATE
    if end_ts and start_ts >= end_ts:
        logger.info(f"[{symbol}-{timeframe}] –î–∞–Ω–Ω—ã–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–æ {END_DATE}")
        return 0
    
    total_loaded = 0
    expected_interval = TF_MS.get(timeframe, 3_600_000)

    while True:
        params = {
            "symbol": api_symbol,
            "interval": timeframe,
            "startTime": start_ts,
            "limit": BINANCE_LIMIT
        }
        if end_ts:
            params["endTime"] = end_ts
            
        try:
            r = requests.get(BASE_URL, params=params, timeout=10)
            r.raise_for_status()
            data = r.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {symbol}-{timeframe}: {e}")
            break

        if not data:
            break

        rows = []
        for k in data:
            current_ts = k[0]
            rows.append((
                symbol, timeframe, current_ts,
                float(k[1]), float(k[2]), float(k[3]), float(k[4]),
                float(k[5]), float(k[7])  # volume, quote_volume
            ))
            start_ts = current_ts + 1  # +1 –º—Å —á—Ç–æ–±—ã –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å —ç—Ç—É –∂–µ —Å–≤–µ—á—É —Å–Ω–æ–≤–∞

        cur.executemany("INSERT OR IGNORE INTO candles VALUES (?,?,?,?,?,?,?,?,?)", rows)
        conn.commit()
        total_loaded += len(rows)
        
        logger.info(f"[{symbol}-{timeframe}] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {total_loaded} —Å–≤–µ—á–µ–π, –¥–æ {datetime.fromtimestamp((start_ts-1)/1000)}")
        
        # –í—ã—Ö–æ–¥: –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞ –∏–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ END_DATE
        if len(data) < BINANCE_LIMIT:
            break
        if end_ts and start_ts >= end_ts:
            logger.info(f"[{symbol}-{timeframe}] –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è {END_DATE}")
            break
            
        time.sleep(BINANCE_SLEEP)
    
    return total_loaded


def load_from_db(conn, symbol, timeframe):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î –≤ DataFrame"""
    df = pd.read_sql_query(
        "SELECT open_time as timestamp, open, high, low, close, volume FROM candles WHERE symbol=? AND timeframe=? ORDER BY open_time",
        conn,
        params=(symbol, timeframe)
    )
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    return df


def add_features(df):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ë–ï–ó –ø–æ–¥—Å–º–∞—Ç—Ä–∏–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ"""
    df = df.copy()
    
    # 1. –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏ –û—Å—Ü–∏–ª–ª—è—Ç–æ—Ä—ã (–¢–ï–ö–£–©–ò–ï, –±–µ–∑ shift)
    df['RSI'] = df.ta.rsi(length=14)
    macd = df.ta.macd()
    df['MACD_line'] = macd['MACD_12_26_9']
    df['MACD_signal'] = macd['MACDs_12_26_9']
    df['MACD_hist'] = macd['MACDh_12_26_9']
    df['ATR'] = df.ta.atr(length=14)
    
    # 2. –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å (–¢–µ–∫—É—â–∞—è Close –∫ –ü—Ä–æ—à–ª–æ–π Close)
    df['Log_Ret'] = np.log(df['close'] / df['close'].shift(1))
    
    # 3. –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–º (–ò–°–ü–†–ê–í–õ–ï–ù–û: –í–∞—Ä–∏–∞–Ω—Ç A –∏–∑ –∫—Ä–∏—Ç–∏–∫–∏)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞ (–≤–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π –±–∞—Ä, —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ –∏ —É–±–∏—Ä–∞–µ—Ç –ª–∞–≥)
    df['volume_ma_20'] = df['volume'].rolling(20, min_periods=1).mean()
    df['Vol_Rel'] = df['volume'] / df['volume_ma_20']
    
    # 4. –õ–∞–≥–∏ (–¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏)
    for col in ['RSI', 'Log_Ret', 'Vol_Rel']:
        for i in range(1, 4):
            df[f'{col}_lag_{i}'] = df[col].shift(i)
    
    # 5. –í—Ä–µ–º—è
    df['hour_sin'] = np.sin(2 * np.pi * df['timestamp'].dt.hour / 24)
    df['day_of_week'] = df['timestamp'].dt.dayofweek
    
    # 6. EMA (–ò–°–ü–†–ê–í–õ–ï–ù–û: –í–∞—Ä–∏–∞–Ω—Ç A –∏–∑ –∫—Ä–∏—Ç–∏–∫–∏ - EMA —Ç–µ–∫—É—â–∞—è, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–µ)
    df['EMA_200'] = df['close'].ewm(span=200, adjust=False).mean()
    df['Trend'] = (df['close'] > df['EMA_200']).astype(int)
    
    # 7. –ü–æ–¥–¥–µ—Ä–∂–∫–∞ / –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ 
    SR_LOOKBACK = 50
    # –£—Ä–æ–≤–Ω–∏ —Å—Ç—Ä–æ–∏–º –ø–æ –ü–†–û–®–õ–´–ú –¥–∞–Ω–Ω—ã–º (shift(1) –û–ë–Ø–ó–ê–¢–ï–õ–ï–ù –¥–ª—è —É—Ä–æ–≤–Ω–µ–π)
    df['Resistance'] = df['high'].rolling(SR_LOOKBACK, min_periods=1).max().shift(1)
    df['Support'] = df['low'].rolling(SR_LOOKBACK, min_periods=1).min().shift(1)
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–∏—Å—Ç–∞–Ω—Ü–∏—é —Å—á–∏—Ç–∞–µ–º –æ—Ç –¢–ï–ö–£–©–ï–ô —Ü–µ–Ω—ã –¥–æ —É—Ä–æ–≤–Ω–µ–π
    df['Dist_to_Resistance'] = (df['Resistance'] - df['close']) / df['ATR']
    df['Dist_to_Support'] = (df['close'] - df['Support']) / df['ATR']
    
    # –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã: —Å—á–∏—Ç–∞–µ–º –ø–æ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω–µ
    sr_range = df['Resistance'] - df['Support']
    df['SR_Position'] = ((df['close'] - df['Support']) / sr_range).clip(0, 1)
    
    df.dropna(inplace=True)
    return df


def add_htf_features(df, htf_df):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∏—á–µ–π —Å—Ç–∞—Ä—à–µ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞.
    –í–ê–ñ–ù–û: –û—Å—Ç–∞–≤–ª—è–µ–º shift(1) –¥–ª—è HTF, —Ç–∞–∫ –∫–∞–∫ timestamps - —ç—Ç–æ Open Time.
    –ë–µ–∑ shift(1) –º—ã –±—ã –∑–∞–≥–ª—è–Ω—É–ª–∏ –≤ '–±—É–¥—É—â–µ–µ' (–≤ –∫–æ–Ω–µ—Ü 4h —Å–≤–µ—á–∏) –ø—Ä–∏ merge_asof.
    """
    htf = htf_df.copy()
    
    # –°—á–∏—Ç–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ 4h (shift(1) —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ó–ê–í–ï–†–®–ï–ù–ù–´–ï —Å–≤–µ—á–∏)
    htf['HTF_RSI'] = htf.ta.rsi(length=14).shift(1)
    htf['HTF_ATR'] = htf.ta.atr(length=14).shift(1)
    htf_macd = htf.ta.macd()
    htf['HTF_MACD_hist'] = htf_macd['MACDh_12_26_9'].shift(1)
    htf['HTF_EMA_50'] = htf['close'].ewm(span=50, adjust=False).mean().shift(1)
    htf['HTF_Trend'] = (htf['close'].shift(1) > htf['HTF_EMA_50']).astype(int)
    htf['HTF_Log_Ret'] = np.log(htf['close'] / htf['close'].shift(1))
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è merge
    htf_cols = ['timestamp', 'HTF_RSI', 'HTF_ATR', 'HTF_MACD_hist',
                'HTF_EMA_50', 'HTF_Trend', 'HTF_Log_Ret']
    htf = htf[htf_cols].dropna()
    
    # merge_asof: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ 1h timestamp –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é 4h –∑–∞–ø–∏—Å—å <= —ç—Ç–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    # –¢.–∫. –º—ã —Å–¥–µ–ª–∞–ª–∏ shift(1) –≤—ã—à–µ, –∑–∞–ø–∏—Å—å 12:00 —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–∏ 08:00-12:00.
    # –≠—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ.
    df = df.sort_values('timestamp')
    htf = htf.sort_values('timestamp')
    df = pd.merge_asof(df, htf, on='timestamp', direction='backward')
    
    df.dropna(inplace=True)
    return df


def triple_barrier_labeling(df):
    """–†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Teacher)"""
    labels = []
    
    closes = df['close'].values
    highs = df['high'].values
    lows = df['low'].values
    atrs = df['ATR'].values
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∏—Å—Ç–æ—Ä–∏–∏
    for i in range(len(df) - HORIZON):
        current_price = closes[i]
        current_atr = atrs[i]
        
        upper_barrier = current_price + (current_atr * ATR_MULTIPLIER)
        lower_barrier = current_price - (current_atr * ATR_MULTIPLIER)
        
        label = 0
        
        # –°–º–æ—Ç—Ä–∏–º –≤ –±—É–¥—É—â–µ–µ –Ω–∞ HORIZON —à–∞–≥–æ–≤
        for j in range(1, HORIZON + 1):
            if i + j >= len(df): break
            
            future_high = highs[i + j]
            future_low = lows[i + j]
            
            if future_high >= upper_barrier:
                label = 1
                break
            if future_low <= lower_barrier:
                label = -1
                break
                
        labels.append(label)
    
    labels.extend([0] * HORIZON)
    df['Target'] = labels
    return df


def save_processed(df, symbol):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É"""
    conn = sqlite3.connect(DB_PATH)
    table_name = symbol.replace('/', '_') + "_features"
    df.to_sql(table_name, conn, if_exists='replace', index=False)
    conn.close()
    logger.info(f"üíæ {symbol} features —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã ({len(df)} —Å—Ç—Ä–æ–∫)")


def main():
    conn = init_db()
    
    for symbol in SYMBOLS:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        logger.info(f"Loading {symbol} {TIMEFRAME} from {START_DATE}...")
        loaded = fetch_data(conn, symbol, TIMEFRAME)
        logger.info(f"{symbol} {TIMEFRAME}: {loaded} new candles")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ä—à–µ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ (4h)
        logger.info(f"Loading {symbol} {HTF_TIMEFRAME} from {START_DATE}...")
        htf_loaded = fetch_data(conn, symbol, HTF_TIMEFRAME)
        logger.info(f"{symbol} {HTF_TIMEFRAME}: {htf_loaded} new candles")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ë–î –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        df = load_from_db(conn, symbol, TIMEFRAME)
        htf_df = load_from_db(conn, symbol, HTF_TIMEFRAME)
        
        if len(df) > 0 and len(htf_df) > 0:
            df = add_features(df)
            df = add_htf_features(df, htf_df)
            df = triple_barrier_labeling(df)
            save_processed(df, symbol)
            logger.info(f"{symbol}: saved {len(df)} rows with HTF + S/R features")
        else:
            logger.warning(f"{symbol}: no data in DB")
    
    conn.close()


if __name__ == '__main__':
    main()